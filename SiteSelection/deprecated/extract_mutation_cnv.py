#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# @Time    : 2022/02/11
# @Author  : zhangsiwen
# @contact : zhang.siwen@puruijizhun.com
# @LastModified: 2022/03/22
# @ChangeLog
#     20220211, first version
#     20220304, add --source
#     20220322, add 'picard' to --source, re-organize functions


import argparse
import pandas as pd
import numpy as np


def GetArgs():
    parser = argparse.ArgumentParser(description='Calculate copy number logR from BAF file and copynumber result', formatter_class=argparse.RawTextHelpFormatter)
    parser._action_groups.pop()
    required = parser.add_argument_group('Required arguments')
    required.add_argument('--baf', help='baf file generated by calculate_baf_platypus.py', action='store', dest='baf', required=True)
    required.add_argument('--cnv', help='copy number file from VarScan copyCaller', action='store', dest='cnv', required=True)
    required.add_argument('--out', help='out file name', action='store', dest='out', required=True)
    optional = parser.add_argument_group('Optional arguments')
    optional.add_argument('--source', help='''source of copy number result, default [cnvkit], \n"cnvkit" stands for cns file from cnvkit caller, \n"varscan2" stands for called file from "varscan copyCaller", \n"picard" stands for perTarget.coverage file from "picard CollectHsMetrics" ''', default='cnvkit', choices=['cnvkit','varscan2', 'picard'], action='store', dest='source', required=False)
    args = parser.parse_args()
    return args


'''
baffile = 'P13.normal.platypus.baf.tsv'
cnvfile = '../varscan2copynumber/P13.varscanCopynumber.called'
outfile = 'test.cnv'
source = 'varscan2'
'''


def HeaderBySource(source):
    if source == 'cnvkit':
        #header = ['chromosome', 'start', 'end', 'gene', 'log2', 'cn', 'depth', 'p_ttest', 'probes', 'weight']
        return 'chromosome', 'start', 'end', 'log2'
    elif source == 'varscan2':
        #header = ['chrom', 'chr_start', 'chr_stop', 'num_positions', 'normal_depth', 'tumor_depth', 'adjusted_log_ratio', 'gc_content', 'region_call', 'raw_ratio']
        return 'chrom', 'chr_start', 'chr_stop', 'adjusted_log_ratio'
    elif source == 'picard':
        #header = ['chrom','start','end','length','name','%gc','mean_coverage','normalized_coverage','min_normalized_coverage','max_normalized_coverage','min_coverage','max_coverage','pct_0x','read_count']
        return 'chrom','start','end','mean_coverage'
    

def ExtractBafCnv(baffile, cnvfile, outfile, source):
    # read files
    baf = pd.read_csv(baffile, low_memory=False, sep='\t', comment='#', header=0, index_col=0)
    cnv = pd.read_csv(cnvfile, low_memory=False, sep='\t', comment='#', header=0, index_col=False)
    maf = pd.DataFrame({'chrs':baf['chrs'], 'pos':baf['pos'], 'sample':0})
    # column assignment
    chrom, start, end, logR = HeaderBySource(source)
    if source == 'picard':
        # use median depth as normal, calculate log2(target mean depth / median depth +1) as logR
        median_depth = np.median(cnv[logR])
        cnv[logR] = np.log2(cnv[logR]/median_depth+1)
    # for each site
    for idx in maf.index:
        pos = maf['pos'][idx]
        subcnv = cnv[(cnv[chrom]==maf.loc[idx,'chrs']) & (cnv[start]<=pos) & (cnv[end]>=pos)]
        if not subcnv.empty:
            maf.loc[idx, 'sample'] = list(subcnv[logR])[0]
    maf.to_csv(outfile, sep='\t', mode='w')


def main():
    args = GetArgs()
    ExtractBafCnv(args.baf, args.cnv, args.out, args.source)


if __name__ == '__main__':
    main()